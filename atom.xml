<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[My Blog qcbetter]]></title>
  <link href="http://wiminq.github.io/atom.xml" rel="self"/>
  <link href="http://wiminq.github.io/"/>
  <updated>2014-09-25T07:49:17+08:00</updated>
  <id>http://wiminq.github.io/</id>
  <author>
    <name><![CDATA[Qin Chenbo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[阡陌路由器]]></title>
    <link href="http://wiminq.github.io/blog/2014/09/23/qian-mo-lu-you-qi/"/>
    <updated>2014-09-23T23:35:05+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/09/23/qian-mo-lu-you-qi</id>
    <content type="html"><![CDATA[<p><img src="http://ww1.sinaimg.cn/large/005KCLTgtw1ekmu14835yj31kw0zkwns.jpg" alt="阡陌路由器" /></p>

<h2>概述</h2>

<p>阡陌公司是由郑州大学信息工程学院计算机科学技术专业同学组的九人团队创立的，公司的主要目的是普通的路由器的基础上，加入一些特殊的功能，主打翻墙和去广告功能，看视频等无广告，自由浏览google、Facebook等国外网站网站，方便查阅国外的文献资料等等。其次流量定向，不浪费，速度上网的速度。还做到了网络云存储，方便设备与设备之间的同步。价格便宜，多功能合一，简单易上手。</p>

<p>现在我们的生活每时每刻每地已经离不开网络，路由器可以很好的解决这个问题。但是目前我们国内的网络上能获取的资源很有限，我们要开发国外的资源，为我们自己所使用。所以我们产品的竞争力就是可以翻墙到国外，正所谓，外面的世界更精彩，说的就是这个道理吧。</p>

<h2>网络策划方案</h2>

<p>网站名称:阡陌网
域名地址：qcbetter.com</p>

<h3>制作步骤：</h3>

<pre><code>      (1) 确立主题
      (2) 收集资料
      (3) 创建网站
      (4) 编辑网页
      (5) 美化网页
      (6) 维护更新
</code></pre>

<p><code>目的</code></p>

<p>阡陌网站的目的毫无疑问是宣传推销我们的阡陌路由器的产品，介绍它的主要功能，特点，竞争力，产品购买和售后服务和维修。从而更好的将我们的产品投放的市场，拓宽市场需求。</p>

<p><code>网站排版</code></p>

<p>网站主要采用黑白灰色作为主色调，低调中不乏亮点。当我们输入qcbetter.com时，首先映入我们视线的是一副图，图上有几个字”看，阡陌路由器”.醒目的标语让我们一眼就对它产生印象。接着，导航栏上有产品概述（包括实物图和详细的说明书），产品功能，产品购买(包括产品价格和用户需求)，售后服务（包括维修和调制）。图片的右边会有几个常用型号的路由器的简单介绍以及跟我们阡陌路由的对比详解，从而体现我们产品的市场竞争力。其次还有我们路由器在使用过程中的一些问题以及具体的解决方法。图片的下边会有几篇相关文献文章的一些参考，帮助那些喜欢搞科研创新的朋友，方便我们一起互相交流和学习，当然最好我们还会留一些留言板已经我们的邮箱，欢迎广大用户的来信反馈。</p>

<p><code>维护刷新情况</code></p>

<p>由于我们能力，技术水平有限，目前所能做到的就是简单的更新，而且我们只能一起商量着更新的内容，会使得更新的频率大大降低，请大家原谅，但是我们会尽量做到一周更新一次，在广大用户的来信以及我们观察市场的变动和我们获取新的技术能力水平的基础上，不断完善和优化我们的设备。</p>

<p><img src="http://ww4.sinaimg.cn/large/005KCLTgjw1ekodpnkhfpj30f5084mxa.jpg" alt="image" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL的一些性能问题和改进]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/30/mysqlde-%5B%3F%5D-xie-xing-neng-wen-ti-he-gai-jin/"/>
    <updated>2014-08-30T14:03:12+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/30/mysqlde-[?]-xie-xing-neng-wen-ti-he-gai-jin</id>
    <content type="html"><![CDATA[<p>@ 楼方鑫 MySQL并发控制&amp;限流设计</p>

<p>一些性能问题和改进</p>

<p>以及一些他做的修改</p>

<!-- more -->


<hr />

<p>性能:</p>

<p>褒贬不一:</p>

<pre><code>业务需求不一样
掌握力度不同
flash设备与传统设备
对开发人员的支持力度

测试
</code></pre>

<p>实际:读比写强</p>

<pre><code>查询强:
    简单的SQL(PK或者有效的索引查找)
    要求:内存里完成排序,分组统计,无子查询
更新弱:
    写存储引擎日志
    写MySQL binlog
    server&amp;storage层的分布式事物
</code></pre>

<h4>一些问题:</h4>

<ul>
<li>全局锁太多</li>
<li>并发是关键</li>
<li>读写没分开</li>
<li>优化器太弱</li>
</ul>


<p>全局锁太多</p>

<pre><code>- SYS CPU太高
    TRX_list
    read View List
    Lock List
- Spinlock &amp; RW Lock &amp; Mutex
- 临界区太大
- 大锁 (事务表 buffer index commit)
</code></pre>

<p>并发是关键</p>

<pre><code>降低并发减少SYS CPU
合理的并发时程减少锁争用
减少失误表长度 缩短事务表的临界区
控制表的大小,缩短索引维护的临界区
</code></pre>

<p>读写要分开</p>

<pre><code>调整优化应用的读写比例,MySQL无法分别控制,以及配合应用的读写比例
</code></pre>

<p>优化器弱:SQL写法</p>

<pre><code>子查询 差
join 差
索引选择 不可靠
</code></pre>

<h4>改进:</h4>

<ul>
<li>多buffer pool(5.5)</li>
<li>读写事物双队列(5.6)</li>
<li>读事物优化&amp;索引全局锁(5.7)</li>
</ul>


<p>多Buffer Pool</p>

<pre><code>代码重构 &amp; Plugin API重构
MySQL 5.5的主要改进
不能按指表定Buffer Pool,运气重要
代码中到处可见的kernel_mutex
读写互相影响很重要
</code></pre>

<p>读写事物双队列</p>

<pre><code>MySQL 5.6在不见了kernel_mutex。
最重要的是读写事务分了不同的队列。
    ro_trx_list
    rw_trx_list
读写操作并发的情况明显改善。
</code></pre>

<p>读事物优化&amp;索引全局锁</p>

<pre><code>查询不需要申请事物ID
    自动识别只读操作
    不再申请事物ID,减轻死锁检测的代价
去掉索引全局锁
    按索引range查询得到明显改善
    索引增大时DML的速度明显改善
</code></pre>

<hr />

<h3>并发控制:(这应该是他得特色)</h3>

<p>4.1 操作分类
4.2 读写分开
4.3 事务分类
4.4 查询分类
4.5 控制机制
4.6 效果测试</p>

<p>4.1 操作分类</p>

<pre><code>查询
    复杂查询
    简单查询
更新
    简单事务    
    复杂事务
</code></pre>

<p>4.2 读写分开</p>

<pre><code>限定总的并发数
限定查询的并发数
限定事务的并发数
</code></pre>

<p>4.3 事务分类</p>

<pre><code>简单事务
    Auto Commit模式
    每个DML语句后自动Commit
复杂事务
    非Auto Commit模式
    由多个DML构成一个语句
</code></pre>

<p>4.4 查询分类</p>

<pre><code>简单查询
    Auto Commit模式
    根据PK或索引查找少量记录
复杂查询
    Auto Commit模式
    包含子查询、分组统计、没有Where条件等
事务查询
    人为事务或非Auto Commit下的查询
</code></pre>

<p>4.5 控制机制
    <img src="http://ww2.sinaimg.cn/mw1024/005KCLTgtw1ejumhvn5pdj30yi0luwhv.jpg" alt="image" /></p>

<p>4.6 效果测试</p>

<pre><code>效果很明显
    10W QPS 7W TPS
建一个有24个字段的表。
按第二索引选择中间的两个字段，平均返回10条记录。
并行度
8，16，32，64，128，256，512，1024，2048，4096，8192，16384  
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[InnoDB的MVCC策略]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/29/innodbde-mvccce-lue/"/>
    <updated>2014-08-29T23:55:27+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/29/innodbde-mvccce-lue</id>
    <content type="html"><![CDATA[<p>MVCC</p>

<pre><code>介绍
实现
    Oracle
    InnoDB
    PostgreSQL
</code></pre>

<hr />

<p>MVCC优势:</p>

<pre><code>高并发
    读写不阻塞
    不同数据库的可见性定义(?)
低加锁开销
    读不加锁
    OLTP 读写4:1
</code></pre>

<p>MVCC实现:</p>

<pre><code>基于时间戳:oracle
基于事物ID:InnoDB postgre

实现粒度:
    页级:Oracle
    行级:InnoDB Postgres
</code></pre>

<hr />

<h3>InnoDB MVCC实现:</h3>

<!-- more -->


<p>关键字</p>

<pre><code>基于事物ID
行级多版本
回滚段
</code></pre>

<p><code>事物ID</code></p>

<pre><code>唯一标示一个事物
递增:新事物对应更大的事物ID
64位.8byte
</code></pre>

<h4>MVCC扩展结构:</h4>

<p>聚簇索引</p>

<pre><code>记录扩展(系统列)
    DB_TRX_ID
    ROLLBACK_PTR
    Delete_Bit
</code></pre>

<p>二级索引</p>

<pre><code>记录扩展
    Delete_Bit      

页面扩展
    DB_MAX_ID(作用:index only scan)
</code></pre>

<h4>更新处理</h4>

<p>Delete:</p>

<pre><code>聚簇索引
    设置Delete_Bit位,前项写入回滚段
    前项包括系统列,#二级索引属性列#
二级索引
    设置Delete_Bit位
</code></pre>

<p>Update:</p>

<pre><code>聚簇索引
    原地更新,前项写入回滚段
二级索引
    clone&amp; update 原项设置Delete_Bit(#不物理删除#)
</code></pre>

<h4>可见性判断</h4>

<p>原理- 给定事务Tx,所有在事务Tx开始时已经提交的事务做的更新是可见的(snapshot read)ReadView- 每个事务,都有read_view结构,通过此判断可见性- low_limit_id: 事务id >= 的所做的修改,均不可见 - up_limit_id: 事务id &lt; 的所做的修改,一定可见 - trx_ids: 事务开始时,活跃事务链表</p>

<h4>Undo</h4>

<p>事务Undo- insert_undo链表 • update_undo链表可见版本构造(记录级)- 1. read 最新版本,判断可见性- 2. 根据ROLLBACK_PTR回滚到前一版本
- 3. 继续步骤1</p>

<h4>Purge</h4>

<p>功能</p>

<ul>
<li>回收聚簇/二级索引上的删除项方式</li>
<li>定期唤醒purge线程- 遍历undo日志,构造索引记录,查找并删除- 一次回收20项undo pages :n_pages_handled = 20不足- 为了能够删除二级索引记录,undo中必须记录完整索引项思考- 为什么需要做purge?</li>
</ul>


<h3>总结:</h3>

<p><code>优势</code></p>

<ul>
<li>实现简单(相对oracle)</li>
<li>行级多版本, 不存在false violation</li>
</ul>


<p><code>缺点</code></p>

<ul>
<li>记录开销增加(系统列)</li>
<li>记录不能实时物理删除(行标示)</li>
<li>更新时,undo中需要记录二级索引的所有属性</li>
<li>purge性能差:过期版本不能及时回收;undo日志不能被覆盖</li>
<li>不支持闪回查询</li>
</ul>


<hr />

<p>Thanks @何登成PPT</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL优化之limit分页优化]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/28/sqlyou-hua-zhi-limitfen-ye-you-hua/"/>
    <updated>2014-08-28T11:13:21+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/28/sqlyou-hua-zhi-limitfen-ye-you-hua</id>
    <content type="html"><![CDATA[<p>SQL优化之limit分页优化</p>

<h4>分页优化</h4>

<p>例一</p>

<pre><code>select  *  from t where sellerid=100 limit 100000，20
优化写法(还有别的写法)
select t1.* from  t t1,(select id from t  sellerid=100 limit 100000，20) t2 where t1.id=t2.id;
优化后的翻页写法，先查询翻页中需要的N条数据的主键id，在根据主键id回表查询所需要的N条数据，此过程中查询N条数据的主键ID在索引中完成
注意：需要在t表的sellerid字段上创建索引
</code></pre>

<!-- more -->


<p>例二</p>

<pre><code>select id, ... from t_buyer 
where sellerId = 765922982 and gmt_modified &gt;= '1970-01-01 08:00:00' 
and gmt_modified &lt;= '2013-06-05 17:11:31'   
limit 255000, 5000

改为:
select t2.* from 
(select id from t_buyer where sellerId = 765922982   
and gmt_modified &gt;= '1970-01-01 08:00:00'   
and gmt_modified &lt;= '2013-06-05 17:11:31'  
limit 255000, 5000）t1,t_buyer t2 where t1.id=t2.id
</code></pre>

<hr />

<p><del><code>limit分页优化 待补充</code></del></p>

<pre><code>limit 1000,10 
    where id &gt;=1000 order by id limit 10;
select id,title,create_date from x order by create_date asc limit 1000,10;
select a.id,a.title,a.create_date from x order by create_date asc limit (1000,1) b on a.id&gt;= b.id limit 10;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL优化之子查询优化]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/28/sqlyou-hua-zhi-zi-cha-xun-you-hua/"/>
    <updated>2014-08-28T11:11:18+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/28/sqlyou-hua-zhi-zi-cha-xun-you-hua</id>
    <content type="html"><![CDATA[<p><code>mysql的处理逻辑是遍历test_pic表中的每一条记录，代入到子查询中中去
而不是先将子查询中的结果集计算出来，然后在与test_pic表关联</code></p>

<p>最佳实践：
子查询在mysql的常见的5.0，5.1，5.5版本中都存在较大风险，使用不当则会造
成严重的性能问题，建议将子查询改为关联的形式：</p>

<!-- more -->


<p>SQL优化之子查询优化</p>

<p><code>5.6之前的子查询</code></p>

<pre><code>select * from A where filed in (select field from B where id = 'xxx');
可以内层临时表,再查再撤销
select  a.* from A a join (select field from B where id = 'xxx') on a.filed = b.filed
</code></pre>

<hr />

<p>例一</p>

<pre><code>select count(*) from test_pic as bi where bi.time in 
(select MAX(time) from test_pic where PIC_TYPE=1 GROUP BY BUILDING_ID) 
GROUP BY bi.BUILDING_ID;
</code></pre>

<p><code>mysql的处理逻辑是遍历test_pic表中的每一条记录，代入到子查询中中去
而不是先将子查询中的结果集计算出来，然后在与test_pic表关联</code></p>

<p>改写为：</p>

<pre><code>select count(*) from test_pic as bi , 
(select MAX(time) as time from test_pic 
where PIC_TYPE=1 GROUP BY BUILDING_ID) b 
where bi.time = b.time GROUP BY bi.BUILDING_ID;
</code></pre>

<p>最佳实践：
子查询在mysql的常见的5.0，5.1，5.5版本中都存在较大风险，使用不当则会造
成严重的性能问题，建议将子查询改为关联的形式：
在oracle迁移到mysql的时候，使用Mysql 5.6的版本，可以避免麻烦的子查询改写</p>

<p>参考资料:
RDS博客</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一些数据库问题优化思路]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/28/%5B%3F%5D-xie-shu-ju-ku-wen-ti-you-hua-si-lu/"/>
    <updated>2014-08-28T11:08:12+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/28/[?]-xie-shu-ju-ku-wen-ti-you-hua-si-lu</id>
    <content type="html"><![CDATA[<p>一些数据库问题优化思路(所有的都是一样,先定位问题 再针对性优化)</p>

<p>(比较水的一篇,具体详细的优化措施别的文章里有)</p>

<p>定位瓶颈:</p>

<p>是哪里有问题</p>

<ul>
<li>CPU;</li>
<li>IO;</li>
<li>连接数;</li>
<li>DISK(空间问题)</li>
</ul>


<p>设计优化:</p>

<ul>
<li>水平拆分:业务拆分 拆库</li>
<li>cache+静态文件CDN</li>
<li>读写分离</li>
<li>数据库设计:索引设计;主键设计;引擎;字段设计</li>
</ul>


<p>SQL优化:</p>

<ul>
<li>分页;</li>
<li>排序;</li>
<li>索引;</li>
<li>子查询</li>
</ul>


<!-- more -->


<p>设计优化:</p>

<pre><code>自增ID主键:考虑到插入性能;二级索引空间;隐藏主键的问题
</code></pre>

<p>索引设计:</p>

<pre><code>索引设计基于query:
    application sql
    slow log
    不仅仅是select需要索引,update.delete也需要添加
要点:
select a from table where b=1 and c=2 order by d desc;
    A 评估参与运算的结果集范围
        b,c
    B 参与排序的字段
        b,c,d
    C 覆盖索引
        b,c,d,a
误区:
    对查询条件的每个字段建单列索引
    对查询的所有字段建组合索引
</code></pre>

<h3>SQL优化</h3>

<p>一 分页优化(详细见博客另一篇文章)</p>

<p>二 隐式转换导致的索引失效</p>

<p>三 子查询问题(详细见另一篇文章)</p>

<h4>分页优化</h4>

<p>例一</p>

<pre><code>select  *  from t where sellerid=100 limit 100000，20
优化写法(还有别的写法)
select t1.* from  t t1,(select id from t  sellerid=100 limit 100000，20) t2 where t1.id=t2.id;
优化后的翻页写法，先查询翻页中需要的N条数据的主键id，在根据主键id回表查询所需要的N条数据，此过程中查询N条数据的主键ID在索引中完成
注意：需要在t表的sellerid字段上创建索引
</code></pre>

<p>例二</p>

<pre><code>select id, ... from t_buyer 
where sellerId = 765922982 and gmt_modified &gt;= '1970-01-01 08:00:00' 
and gmt_modified &lt;= '2013-06-05 17:11:31'   
limit 255000, 5000

改为:
select t2.* from 
(select id from t_buyer where sellerId = 765922982   
and gmt_modified &gt;= '1970-01-01 08:00:00'   
and gmt_modified &lt;= '2013-06-05 17:11:31'  
limit 255000, 5000）t1,t_buyer t2 where t1.id=t2.id
</code></pre>

<h4>子查询优化</h4>

<p><code>5.6之前的子查询</code></p>

<pre><code>select * from A where filed in (select field from B where id = 'xxx');
可以内层临时表,再查再撤销
select  a.* from A a join (select field from B where id = 'xxx') on a.filed = b.filed
</code></pre>

<hr />

<p>例一</p>

<pre><code>select count(*) from test_pic as bi where bi.time in 
(select MAX(time) from test_pic where PIC_TYPE=1 GROUP BY BUILDING_ID) 
GROUP BY bi.BUILDING_ID;
</code></pre>

<p><code>mysql的处理逻辑是遍历test_pic表中的每一条记录，代入到子查询中中去
而不是先将子查询中的结果集计算出来，然后在与test_pic表关联</code></p>

<p>改写为：</p>

<pre><code>select count(*) from test_pic as bi , 
(select MAX(time) as time from test_pic 
where PIC_TYPE=1 GROUP BY BUILDING_ID) b 
where bi.time = b.time GROUP BY bi.BUILDING_ID;
</code></pre>

<p>最佳实践：
子查询在mysql的常见的5.0，5.1，5.5版本中都存在较大风险，使用不当则会造
成严重的性能问题，建议将子查询改为关联的形式：
在oracle迁移到mysql的时候，使用Mysql 5.6的版本，可以避免麻烦的子查询改写</p>

<p>参考资料:
RDS博客</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[InnoDB O_DIRECT选项]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/innodb-o-directxuan-xiang/"/>
    <updated>2014-08-27T20:06:50+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/innodb-o-directxuan-xiang</id>
    <content type="html"><![CDATA[<p><code>innodb_flush_method</code>通常设置为<code>O_DIRECT</code></p>

<p>官方文档推荐,一般说就是启用后文件的写入将绕过操作系统缓存,直接写文件.这样虽然不会有更好的性能但是DB有自己的缓存不需要了.</p>

<p>但是不管innodb_flush_method的设置为何值，在刷新脏页时都会调用<code>fsync</code>操作，具体见函数buf_flush_buffered_writes.</p>

<p>但是为什么已经打开了O_DIRECT标识为什么还要fsync确保文件写入呢?</p>

<!-- more -->


<hr />

<p>因为有些文件系统例如XFS EXT4有inode与之对应,其保存有两部分,元数据和文件的存储数据.</p>

<p>元数据包含的内容有:</p>

<ul>
<li>文件大小</li>
<li>权限</li>
<li>链接数量</li>
</ul>


<p>可以发现元数据及其重要的，不仅仅是文件最后修改时间、权限等信息，它还包含有指向存储块的信息。若在数据增长时，元数据没有及时更新，那么同样可能会导致数据丢失的情况。</p>

<p>inode中的元数据是保存在inode cache中，inode的保存文件的数据是保存在操作系统缓存中（若未开启O_DIRECT标识）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL Replication中的一些数据丢失问题]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/mysql-replicationzhong-de-%5B%3F%5D-xie-shu-ju-diu-shi-wen-ti/"/>
    <updated>2014-08-27T14:51:43+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/mysql-replicationzhong-de-[?]-xie-shu-ju-diu-shi-wen-ti</id>
    <content type="html"><![CDATA[<ul>
<li>复制中可能遇到的问题</li>
<li>5.5的解决方案</li>
<li>5.7的解决方案</li>
<li>VSR(InnoSQL)实现原理和机制(一句话就是调整了semi-sync的提交与等待顺序)</li>
<li>HA suit和一些条件是什么</li>
</ul>


<!-- more -->


<hr />

<p>MySQL replication</p>

<pre><code>虽然很简单但是很容易出问题,例如1062 1053 1032
@姜承尧:搭建一个严格的符合生产环境复制需求的是有极大挑战的

MySQL 5.6支持crash safe功能可以解决很大一部分问题.

但是用户抱怨MySQL复制不支持数据不丢失的场景,(即使用MySQL复制功能注定要承担数据丢失的风险)虽然可以通过一些应用来完成记录每个操作日志来进行恢复,会比较麻烦
</code></pre>

<p>5.5引入的semi-sync replication</p>

<pre><code>同样会丢失但是丢失的内容会少
@周振兴提出的 enhanced semi-sync replication的想法,并在5.5实现但是性能较差,没有应用
</code></pre>

<p>5.7</p>

<pre><code>实现了类似功能,称为loss-less replication 
还太早
</code></pre>

<p>InnoSQL</p>

<pre><code>借鉴@周振兴的想法,并结合组提交,通过减少fsync的次数来抵消网络的开销,此外可以通过提高组提交的比例来进一步优化性能,在InnoSQL中实现叫:virtual sync replication(VSR)
</code></pre>

<h3>实现原理</h3>

<p>简单来说就是<code>调整了semi-sync的提交与等待顺序</code></p>

<p>原先semi-sync提交顺序是:</p>

<ul>
<li>InnoDB引擎层prepare事务</li>
<li>MySQL层写二进制日志</li>
<li>InnoDB引擎层commit事务</li>
<li>通过复制的dump线程发送二进制日志event</li>
<li><p>等待接受从机的ACK回复</p>

<p>  <code>这样的处理机制会存在这样一个问题，由于步骤4的时候，事务已经提交，那么之前事务所做的修改对其他用户已经是可见的了，那么当发生宕机进行主从切换时，slave上可能会不存在之前已经存在的数据。</code>VSR机制在于改变了3和4的步骤，这样保证在发送二进制日志的event时，事务没有提交，数据不可见，那么当进行主从故障切换时，不会存在上述semi-sync replication的问题。VSR的实现机制见下图</p></li>
</ul>


<p><img src="http://ww2.sinaimg.cn/mw1024/005KCLTgjw1ejr6u2ruf5j30ng0e7wgb.jpg" alt="VSR" /></p>

<p>有用户可能会对VSR的性能抱有担心，的确网络的延迟是无法避免的，这决定了VSR的性能会比异步的复制要差。但是VSR的性能会比semi-sync复制的性能要好很多。其实这是非常容易理解的，因为<code>步骤3，4交换顺序后，可以极大的提高组提交的比例，从而减少fysnc的次数，提高性能，这就是前面说的，通过减少fsync来减缓网络延迟带来的开销</code>。Facebook也有类似VSR的实现机制（FB称之为semi synchronous replication），他们也证实了VSR的性能要比semi-sync来得好</p>

<p>仅仅通过VSR机制就能保证主从数据的完全一致性吗？很可惜，还是不能。VSR还是与semi-sync一样，存在故障切换后，原master服务器的数据比slave多的情况。这是因为上述的步骤2已经写二进制日志了，master故障恢复后依然会提交该事务，但是这部分二进制日志可能会没有传送到slave。<code>但是VSR和semi-sync不同的是，由于事务还在提交过程中，数据对其他事务不可见，这意味着，这部分已经写入到二进制日志的事务可以回滚</code>。这部分的操作，最早通过外部脚本来控制，后来InnoSQL决定将这部分的工作交由数据库自己来完成，最后以一个高可用的套件形式来展现给用户，那么这部分的操作对用户来说就都是透明的了:<strong><code>HA Suite</code></strong></p>

<p><code>VSR来说最为重要的就是网络，对于网络的要求极高</code></p>

<hr />

<p>参考链接:
<a href="http://www.innomysql.net/article/7403.html">http://www.innomysql.net/article/7403.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL并行复制]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/mysqlbing-xing-fu-zhi/"/>
    <updated>2014-08-27T14:24:44+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/mysqlbing-xing-fu-zhi</id>
    <content type="html"><![CDATA[<ul>
<li>MySQL复制中容易遇到的问题</li>
<li>各家的解决方案</li>
<li>比较完美的并行复制的配置</li>
</ul>


<!-- more -->


<hr />

<p>MySQL slave 的延迟问题普遍</p>

<p>由于这个原因,很难将读取操作放到从机,造成了以下潜规则</p>

<pre><code>实时性要求不高的读取操作可以放到slave,实时性高的还得放到master
从机仅能做前一天的统计查询(夸张了)
</code></pre>

<p>网易之前</p>

<pre><code>之前易信 RDS也遇到这些问题,
V3版本之前解决方案是 使用batch commit,即批量提交,由于减少commit次数也有效,
    重点是对二进制格式没有要求,
    缺点是还是单线程回放,不能充分利用磁盘性能,存储引擎需要是innodb或者tukudb
</code></pre>

<p>淘宝:</p>

<pre><code>并行复制是基于row格式(后来我个人和阿里聊说他们这种方案也是不采用,有更好的,类似与一个中间件 binlog解析后做处理)
@姜承尧:对并行的判断会比较复杂,并且全局hash表感觉会是一个瓶颈
</code></pre>

<p>MariaDB</p>

<pre><code>一个组提交中的事物可以并行执行.(堪称完美)
一个组提交中的事物之间没有冲突,否则不可能进行这个阶段.
MariaDB的实现基于GTID,
</code></pre>

<p>网易之后:InnoSQL</p>

<pre><code>但是5.5没有GTID,他们增加了一个event类型,称之为Gcid_event,表示组提交的编号
一个binlog_commit_wait_user参数表示等待多久再组提交,这样的参数对共享存储有极大帮助,根据测试结果,响应时间下降3%,但是共享存储的IO使用率下降50%

还有一个重要特性:crash safe:服务器或者复制服务出现任何问题,主从数据是完全正确的,他们将relay-log作为一张表,这个和5.6官方处理方式是一样的,但是和percona不一样,
</code></pre>

<p>percona方案:</p>

<pre><code>将slave服务器的二进制位置写入innodb的事物段头,回复时通过这一段来替换relay-info文件,这样看似简单易懂,但是只支持innodb存储引擎.
</code></pre>

<p><strong>实现并行复制最为关键</strong>是order commit的实现,即事物在slave服务器是并行执行的,但是提交顺序和master服务器一致的.这样能保证主从产生二进制日志的顺序是一致的. <code>实现最复杂的是对出错的处理</code>(具体没说)</p>

<h3>并行复制配置</h3>

<p>一个完美crash-safe并行复制的环境</p>

<p>master:</p>

<pre><code>[mysqld]
server-id=xxx
log-bin=xxx
sync_binlog=1 #保证master crash safe，该参数必须设置为1
innodb_support_xa=1 #保证master crash safe，该参数必须设置为1
binlog_commit_wait_count=xxx #根据自身业务进行调整
binlog_commit_wait_usec=xxx #根据自身业务进行调整
enable_table_relay_info=1 #如果需要进行双主的配置
</code></pre>

<p>slave:</p>

<pre><code>[mysqld]
server-id = xxx
log-bin = xxx
enable_table_relay_info = 1
enable_muti_replication = 1 #启用并行复制
slave_parallel_threads = 32 #并行复制的线程数
relay_log_recovery = 1 #从机crash safe要求重新同步master日志
</code></pre>

<p>这样能保证并行复制crash safe 但是不保证failover不丢数据</p>

<p>(<code>sync-binlog=1 supprot_xa=1了不就本来就是crash-safe的么?</code>这个不是很清楚,还是这个功能是有些夸大了?) 哦 他这个safe 是指relay log的safe啊..</p>

<p>不丢失需要开启InnoSQL的VSR功能(参考下一篇文章)</p>

<hr />

<p>参考链接:</p>

<p><a href="http://www.innomysql.net/article/6276.html">http://www.innomysql.net/article/6276.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NOSQL数据模型(HBase Cassandra)]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/nosqlshu-ju-mo-xing-hbase-cassandra/"/>
    <updated>2014-08-27T11:39:15+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/nosqlshu-ju-mo-xing-hbase-cassandra</id>
    <content type="html"><![CDATA[<p>昨天看了</p>

<!-- more -->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Octopress 搭建过程]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/octopress-da-jian-guo-cheng/"/>
    <updated>2014-08-27T10:43:57+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/octopress-da-jian-guo-cheng</id>
    <content type="html"><![CDATA[<h1>Octopress 搭建过程</h1>

<p>git clone git://github.com/imathis/octopress.git octopress</p>

<p>cd octopress</p>

<p>gem install bundler</p>

<p>rbenv rehash</p>

<p>bundle install</p>

<p>rake install</p>

<!-- more -->


<p>rake setup_github_pages</p>

<pre><code>git@github.com:wiminq/wiminq.github.io.git
</code></pre>

<p>rake generate</p>

<p>rake deploy</p>

<p>git add .
git commit -m &lsquo;test&rsquo;
git push origin source</p>

<p>echo &lsquo;www.qcbetter.com&rsquo; >> source/CNAME</p>

<p>alias rake=&lsquo;noglob rake&rsquo;</p>

<p>rake new_post[&ldquo;first &rdquo;]</p>

<pre><code>vim source/_posts/2014-08-27-test.markdown
</code></pre>

<p>rake new_page[super-awesome]</p>

<pre><code>rake watch
rake preview
</code></pre>

<p>vim _config.yml</p>

<p>rake generate</p>

<p>rake deploy</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/first/"/>
    <updated>2014-08-27T10:17:29+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/first</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
</feed>
