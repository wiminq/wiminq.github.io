<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[My Blog qcbetter]]></title>
  <link href="http://wiminq.github.io/atom.xml" rel="self"/>
  <link href="http://wiminq.github.io/"/>
  <updated>2014-08-28T11:09:46+08:00</updated>
  <id>http://wiminq.github.io/</id>
  <author>
    <name><![CDATA[Qin Chenbo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[一些数据库问题优化思路]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/28/%5B%3F%5D-xie-shu-ju-ku-wen-ti-you-hua-si-lu/"/>
    <updated>2014-08-28T11:08:12+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/28/[?]-xie-shu-ju-ku-wen-ti-you-hua-si-lu</id>
    <content type="html"><![CDATA[<p>一些数据库问题优化思路(所有的都是一样,先定位问题 再针对性优化)</p>

<p>(比较水的一篇,具体详细的优化措施别的文章里有)</p>

<p>定位瓶颈:</p>

<p>是哪里有问题</p>

<ul>
<li>CPU;</li>
<li>IO;</li>
<li>连接数;</li>
<li>DISK(空间问题)</li>
</ul>


<p>设计优化:</p>

<ul>
<li>水平拆分:业务拆分 拆库</li>
<li>cache+静态文件CDN</li>
<li>读写分离</li>
<li>数据库设计:索引设计;主键设计;引擎;字段设计</li>
</ul>


<p>SQL优化:</p>

<ul>
<li>分页;</li>
<li>排序;</li>
<li>索引;</li>
<li>子查询</li>
</ul>


<!-- more -->


<p>设计优化:</p>

<pre><code>自增ID主键:考虑到插入性能;二级索引空间;隐藏主键的问题
</code></pre>

<p>索引设计:</p>

<pre><code>索引设计基于query:
    application sql
    slow log
    不仅仅是select需要索引,update.delete也需要添加
要点:
select a from table where b=1 and c=2 order by d desc;
    A 评估参与运算的结果集范围
        b,c
    B 参与排序的字段
        b,c,d
    C 覆盖索引
        b,c,d,a
误区:
    对查询条件的每个字段建单列索引
    对查询的所有字段建组合索引
</code></pre>

<h3>SQL优化</h3>

<p>一 分页优化(详细见博客另一篇文章)</p>

<p>二 隐式转换导致的索引失效</p>

<p>三 子查询问题(详细见另一篇文章)</p>

<h4>分页优化</h4>

<p>例一</p>

<pre><code>select  *  from t where sellerid=100 limit 100000，20
优化写法(还有别的写法)
select t1.* from  t t1,(select id from t  sellerid=100 limit 100000，20) t2 where t1.id=t2.id;
优化后的翻页写法，先查询翻页中需要的N条数据的主键id，在根据主键id回表查询所需要的N条数据，此过程中查询N条数据的主键ID在索引中完成
注意：需要在t表的sellerid字段上创建索引
</code></pre>

<p>例二</p>

<pre><code>select id, ... from t_buyer 
where sellerId = 765922982 and gmt_modified &gt;= '1970-01-01 08:00:00' 
and gmt_modified &lt;= '2013-06-05 17:11:31'   
limit 255000, 5000

改为:
select t2.* from 
(select id from t_buyer where sellerId = 765922982   
and gmt_modified &gt;= '1970-01-01 08:00:00'   
and gmt_modified &lt;= '2013-06-05 17:11:31'  
limit 255000, 5000）t1,t_buyer t2 where t1.id=t2.id
</code></pre>

<h4>子查询优化</h4>

<p><code>5.6之前的子查询</code></p>

<pre><code>select * from A where filed in (select field from B where id = 'xxx');
可以内层临时表,再查再撤销
select  a.* from A a join (select field from B where id = 'xxx') on a.filed = b.filed
</code></pre>

<hr />

<p>例一</p>

<pre><code>select count(*) from test_pic as bi where bi.time in 
(select MAX(time) from test_pic where PIC_TYPE=1 GROUP BY BUILDING_ID) 
GROUP BY bi.BUILDING_ID;
</code></pre>

<p><code>mysql的处理逻辑是遍历test_pic表中的每一条记录，代入到子查询中中去
而不是先将子查询中的结果集计算出来，然后在与test_pic表关联</code></p>

<p>改写为：</p>

<pre><code>select count(*) from test_pic as bi , 
(select MAX(time) as time from test_pic 
where PIC_TYPE=1 GROUP BY BUILDING_ID) b 
where bi.time = b.time GROUP BY bi.BUILDING_ID;
</code></pre>

<p>最佳实践：
子查询在mysql的常见的5.0，5.1，5.5版本中都存在较大风险，使用不当则会造
成严重的性能问题，建议将子查询改为关联的形式：
在oracle迁移到mysql的时候，使用Mysql 5.6的版本，可以避免麻烦的子查询改写</p>

<p>参考资料:
RDS博客</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[InnoDB O_DIRECT选项]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/innodb-o-directxuan-xiang/"/>
    <updated>2014-08-27T20:06:50+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/innodb-o-directxuan-xiang</id>
    <content type="html"><![CDATA[<p><code>innodb_flush_method</code>通常设置为<code>O_DIRECT</code></p>

<p>官方文档推荐,一般说就是启用后文件的写入将绕过操作系统缓存,直接写文件.这样虽然不会有更好的性能但是DB有自己的缓存不需要了.</p>

<p>但是不管innodb_flush_method的设置为何值，在刷新脏页时都会调用<code>fsync</code>操作，具体见函数buf_flush_buffered_writes.</p>

<p>但是为什么已经打开了O_DIRECT标识为什么还要fsync确保文件写入呢?</p>

<!-- more -->


<hr />

<p>因为有些文件系统例如XFS EXT4有inode与之对应,其保存有两部分,元数据和文件的存储数据.</p>

<p>元数据包含的内容有:</p>

<ul>
<li>文件大小</li>
<li>权限</li>
<li>链接数量</li>
</ul>


<p>可以发现元数据及其重要的，不仅仅是文件最后修改时间、权限等信息，它还包含有指向存储块的信息。若在数据增长时，元数据没有及时更新，那么同样可能会导致数据丢失的情况。</p>

<p>inode中的元数据是保存在inode cache中，inode的保存文件的数据是保存在操作系统缓存中（若未开启O_DIRECT标识）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL Replication中的一些数据丢失问题]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/mysql-replicationzhong-de-%5B%3F%5D-xie-shu-ju-diu-shi-wen-ti/"/>
    <updated>2014-08-27T14:51:43+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/mysql-replicationzhong-de-[?]-xie-shu-ju-diu-shi-wen-ti</id>
    <content type="html"><![CDATA[<ul>
<li>复制中可能遇到的问题</li>
<li>5.5的解决方案</li>
<li>5.7的解决方案</li>
<li>VSR(InnoSQL)实现原理和机制(一句话就是调整了semi-sync的提交与等待顺序)</li>
<li>HA suit和一些条件是什么</li>
</ul>


<!-- more -->


<hr />

<p>MySQL replication</p>

<pre><code>虽然很简单但是很容易出问题,例如1062 1053 1032
@姜承尧:搭建一个严格的符合生产环境复制需求的是有极大挑战的

MySQL 5.6支持crash safe功能可以解决很大一部分问题.

但是用户抱怨MySQL复制不支持数据不丢失的场景,(即使用MySQL复制功能注定要承担数据丢失的风险)虽然可以通过一些应用来完成记录每个操作日志来进行恢复,会比较麻烦
</code></pre>

<p>5.5引入的semi-sync replication</p>

<pre><code>同样会丢失但是丢失的内容会少
@周振兴提出的 enhanced semi-sync replication的想法,并在5.5实现但是性能较差,没有应用
</code></pre>

<p>5.7</p>

<pre><code>实现了类似功能,称为loss-less replication 
还太早
</code></pre>

<p>InnoSQL</p>

<pre><code>借鉴@周振兴的想法,并结合组提交,通过减少fsync的次数来抵消网络的开销,此外可以通过提高组提交的比例来进一步优化性能,在InnoSQL中实现叫:virtual sync replication(VSR)
</code></pre>

<h3>实现原理</h3>

<p>简单来说就是<code>调整了semi-sync的提交与等待顺序</code></p>

<p>原先semi-sync提交顺序是:</p>

<ul>
<li>InnoDB引擎层prepare事务</li>
<li>MySQL层写二进制日志</li>
<li>InnoDB引擎层commit事务</li>
<li>通过复制的dump线程发送二进制日志event</li>
<li><p>等待接受从机的ACK回复</p>

<p>  <code>这样的处理机制会存在这样一个问题，由于步骤4的时候，事务已经提交，那么之前事务所做的修改对其他用户已经是可见的了，那么当发生宕机进行主从切换时，slave上可能会不存在之前已经存在的数据。</code>VSR机制在于改变了3和4的步骤，这样保证在发送二进制日志的event时，事务没有提交，数据不可见，那么当进行主从故障切换时，不会存在上述semi-sync replication的问题。VSR的实现机制见下图</p></li>
</ul>


<p><img src="http://ww2.sinaimg.cn/mw1024/005KCLTgjw1ejr6u2ruf5j30ng0e7wgb.jpg" alt="VSR" /></p>

<p>有用户可能会对VSR的性能抱有担心，的确网络的延迟是无法避免的，这决定了VSR的性能会比异步的复制要差。但是VSR的性能会比semi-sync复制的性能要好很多。其实这是非常容易理解的，因为<code>步骤3，4交换顺序后，可以极大的提高组提交的比例，从而减少fysnc的次数，提高性能，这就是前面说的，通过减少fsync来减缓网络延迟带来的开销</code>。Facebook也有类似VSR的实现机制（FB称之为semi synchronous replication），他们也证实了VSR的性能要比semi-sync来得好</p>

<p>仅仅通过VSR机制就能保证主从数据的完全一致性吗？很可惜，还是不能。VSR还是与semi-sync一样，存在故障切换后，原master服务器的数据比slave多的情况。这是因为上述的步骤2已经写二进制日志了，master故障恢复后依然会提交该事务，但是这部分二进制日志可能会没有传送到slave。<code>但是VSR和semi-sync不同的是，由于事务还在提交过程中，数据对其他事务不可见，这意味着，这部分已经写入到二进制日志的事务可以回滚</code>。这部分的操作，最早通过外部脚本来控制，后来InnoSQL决定将这部分的工作交由数据库自己来完成，最后以一个高可用的套件形式来展现给用户，那么这部分的操作对用户来说就都是透明的了:<strong><code>HA Suite</code></strong></p>

<p><code>VSR来说最为重要的就是网络，对于网络的要求极高</code></p>

<hr />

<p>参考链接:
<a href="http://www.innomysql.net/article/7403.html">http://www.innomysql.net/article/7403.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL并行复制]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/mysqlbing-xing-fu-zhi/"/>
    <updated>2014-08-27T14:24:44+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/mysqlbing-xing-fu-zhi</id>
    <content type="html"><![CDATA[<ul>
<li>MySQL复制中容易遇到的问题</li>
<li>各家的解决方案</li>
<li>比较完美的并行复制的配置</li>
</ul>


<!-- more -->


<hr />

<p>MySQL slave 的延迟问题普遍</p>

<p>由于这个原因,很难将读取操作放到从机,造成了以下潜规则</p>

<pre><code>实时性要求不高的读取操作可以放到slave,实时性高的还得放到master
从机仅能做前一天的统计查询(夸张了)
</code></pre>

<p>网易之前</p>

<pre><code>之前易信 RDS也遇到这些问题,
V3版本之前解决方案是 使用batch commit,即批量提交,由于减少commit次数也有效,
    重点是对二进制格式没有要求,
    缺点是还是单线程回放,不能充分利用磁盘性能,存储引擎需要是innodb或者tukudb
</code></pre>

<p>淘宝:</p>

<pre><code>并行复制是基于row格式(后来我个人和阿里聊说他们这种方案也是不采用,有更好的,类似与一个中间件 binlog解析后做处理)
@姜承尧:对并行的判断会比较复杂,并且全局hash表感觉会是一个瓶颈
</code></pre>

<p>MariaDB</p>

<pre><code>一个组提交中的事物可以并行执行.(堪称完美)
一个组提交中的事物之间没有冲突,否则不可能进行这个阶段.
MariaDB的实现基于GTID,
</code></pre>

<p>网易之后:InnoSQL</p>

<pre><code>但是5.5没有GTID,他们增加了一个event类型,称之为Gcid_event,表示组提交的编号
一个binlog_commit_wait_user参数表示等待多久再组提交,这样的参数对共享存储有极大帮助,根据测试结果,响应时间下降3%,但是共享存储的IO使用率下降50%

还有一个重要特性:crash safe:服务器或者复制服务出现任何问题,主从数据是完全正确的,他们将relay-log作为一张表,这个和5.6官方处理方式是一样的,但是和percona不一样,
</code></pre>

<p>percona方案:</p>

<pre><code>将slave服务器的二进制位置写入innodb的事物段头,回复时通过这一段来替换relay-info文件,这样看似简单易懂,但是只支持innodb存储引擎.
</code></pre>

<p><strong>实现并行复制最为关键</strong>是order commit的实现,即事物在slave服务器是并行执行的,但是提交顺序和master服务器一致的.这样能保证主从产生二进制日志的顺序是一致的. <code>实现最复杂的是对出错的处理</code>(具体没说)</p>

<h3>并行复制配置</h3>

<p>一个完美crash-safe并行复制的环境</p>

<p>master:</p>

<pre><code>[mysqld]
server-id=xxx
log-bin=xxx
sync_binlog=1 #保证master crash safe，该参数必须设置为1
innodb_support_xa=1 #保证master crash safe，该参数必须设置为1
binlog_commit_wait_count=xxx #根据自身业务进行调整
binlog_commit_wait_usec=xxx #根据自身业务进行调整
enable_table_relay_info=1 #如果需要进行双主的配置
</code></pre>

<p>slave:</p>

<pre><code>[mysqld]
server-id = xxx
log-bin = xxx
enable_table_relay_info = 1
enable_muti_replication = 1 #启用并行复制
slave_parallel_threads = 32 #并行复制的线程数
relay_log_recovery = 1 #从机crash safe要求重新同步master日志
</code></pre>

<p>这样能保证并行复制crash safe 但是不保证failover不丢数据</p>

<p>(<code>sync-binlog=1 supprot_xa=1了不就本来就是crash-safe的么?</code>这个不是很清楚,还是这个功能是有些夸大了?) 哦 他这个safe 是指relay log的safe啊..</p>

<p>不丢失需要开启InnoSQL的VSR功能(参考下一篇文章)</p>

<hr />

<p>参考链接:</p>

<p><a href="http://www.innomysql.net/article/6276.html">http://www.innomysql.net/article/6276.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NOSQL数据模型(HBase Cassandra)]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/nosqlshu-ju-mo-xing-hbase-cassandra/"/>
    <updated>2014-08-27T11:39:15+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/nosqlshu-ju-mo-xing-hbase-cassandra</id>
    <content type="html"><![CDATA[<p>昨天看了</p>

<!-- more -->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Octopress 搭建过程]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/octopress-da-jian-guo-cheng/"/>
    <updated>2014-08-27T10:43:57+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/octopress-da-jian-guo-cheng</id>
    <content type="html"><![CDATA[<h1>Octopress 搭建过程</h1>

<p>git clone git://github.com/imathis/octopress.git octopress</p>

<p>cd octopress</p>

<p>gem install bundler</p>

<p>rbenv rehash</p>

<p>bundle install</p>

<p>rake install</p>

<!-- more -->


<p>rake setup_github_pages</p>

<pre><code>git@github.com:wiminq/wiminq.github.io.git
</code></pre>

<p>rake generate</p>

<p>rake deploy</p>

<p>git add .
git commit -m &lsquo;test&rsquo;
git push origin source</p>

<p>echo &lsquo;www.qcbetter.com&rsquo; >> source/CNAME</p>

<p>alias rake=&lsquo;noglob rake&rsquo;</p>

<p>rake new_post[&ldquo;first &rdquo;]</p>

<pre><code>vim source/_posts/2014-08-27-test.markdown
</code></pre>

<p>rake new_page[super-awesome]</p>

<pre><code>rake watch
rake preview
</code></pre>

<p>vim _config.yml</p>

<p>rake generate</p>

<p>rake deploy</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First]]></title>
    <link href="http://wiminq.github.io/blog/2014/08/27/first/"/>
    <updated>2014-08-27T10:17:29+08:00</updated>
    <id>http://wiminq.github.io/blog/2014/08/27/first</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
</feed>
